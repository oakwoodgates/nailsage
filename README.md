# NailSage

**ML Trading Research Platform for Cryptocurrency Markets**

Named after the Great Nailsage Sly, trainer of the Nailmasters, from Hollow Knight.

## ğŸ¯ Overview

NailSage is a production-ready ML trading research platform designed for building, testing, and deploying machine learning trading strategies with rigorous validation and complete reproducibility.

**Status**: Production ML Trading Platform âœ… - Live paper trading operational

## âœ¨ Key Features

- **âœ… Complete Metadata Tracking**: Full data and model provenance for reproducibility
- **âœ… Data Leakage Prevention**: Strict temporal ordering with walk-forward validation
- **âœ… Realistic Backtesting**: Transaction costs, slippage, and leverage simulation
- **âœ… Hybrid Model Registry**: Track configuration intent and training history
- **âœ… Dynamic Feature Engineering**: 18 technical indicators computed on-the-fly
- **âœ… Modular Architecture**: Independent strategies with centralized model management
- **âœ… Binary Classification Models**: SHORT/LONG signals with confidence filtering
- **âœ… Real-Time Execution**: Live paper trading with realistic market simulation
- **âœ… Risk Management**: Per-strategy bankrolls with automatic position sizing
- **âœ… Transparent Logging**: Complete audit trail of signal generation and execution
- **âœ… Production Deployment**: Docker-based multi-strategy execution
- **âœ… Walk-Forward Validation**: Time series cross-validation preventing data leakage

## ğŸš€ Quick Start

### Installation

```bash
# Clone repository
git clone <repository>
cd nailsage

# Install dependencies
pip install -r requirements.txt  # Or use pyproject.toml

# Verify imports
python scripts/verify_imports.py
```

### Generate Data Metadata

```bash
# For a single file
python scripts/generate_data_metadata.py --file data/raw/your_data.parquet

# For entire directory
python scripts/generate_data_metadata.py --dir data/raw
```

### Train and Validate Models

```bash
# Unified train + validate (walk-forward, per-split retrain, saves JSON)
python training/cli/run_train_validate.py --config strategies/dev_scalper_1m_v1.yaml

# Train only
python training/cli/run_train_validate.py --config strategies/dev_scalper_1m_v1.yaml --train-only

# Validate existing model
python training/cli/validate_model.py --config strategies/dev_scalper_1m_v1.yaml --model-id MODEL_ID

# Quick backtest
python training/cli/run_backtest.py --config strategies/dev_scalper_1m_v1.yaml --model-id MODEL_ID
```

### Run Tests

```bash
# Run unit tests (no external env required)
pytest tests/unit/ -v

# Run with coverage
pytest tests/unit/ --cov=. --cov-report=term-missing

# Optional end-to-end training pipeline test (requires RUN_E2E_TRAINING=1)
RUN_E2E_TRAINING=1 pytest tests/integration/training/test_e2e_training_pipeline.py -q

# Integration tests (API + ML pipelines); websocket test is skipped by default
pytest tests/integration -q
```

## Logging

- Training/validation/backtest emit JSON-friendly logs with contextual fields (`strategy`, `version`, `run_id`) and event tags (e.g., `train_start`, `train_timings`, `validation_split`, `validation_aggregate`, `feature_cache_hit`).
- Use `training/cli/run_train_validate.py --summary` for concise metrics output, `--dry-run` for schema/config validation only, and `--force-cache-bust` to bypass feature cache.

### ğŸ³ Docker Quick Start (Recommended for Paper Trading)

Run strategies in production-ready Docker containers with PostgreSQL:

```bash
# 1. Configure environment
cp .env.example .env
# Edit .env with your Kirby API credentials

# 2. Start all services
docker compose up -d

# 3. View logs
docker logs nailsage-binance -f

# 4. Check status
docker compose ps

# 5. Stop services
docker compose down
```

**What's running:**
- PostgreSQL database (port 5433)
- FastAPI dashboard API (port 8001)
- Strategy containers (Binance, Hyperliquid)

**Development workflow:**
```bash
# Make code changes, then rebuild
docker compose build nailsage-binance && docker compose up -d nailsage-binance

# View live predictions
docker logs nailsage-binance --tail 100 -f
```

**Full documentation:** See [docs/DOCKER.md](docs/DOCKER.md) for complete setup, deployment, and troubleshooting guides.

## ğŸ“ Project Structure

```
nailsage/
â”œâ”€â”€ config/                    # Pydantic configuration models
â”‚   â”œâ”€â”€ base.py               # BaseConfig with YAML loading
â”‚   â”œâ”€â”€ data.py               # DataConfig (OHLCV loading)
â”‚   â”œâ”€â”€ feature.py            # FeatureConfig (indicators)
â”‚   â”œâ”€â”€ strategy.py           # StrategyConfig
â”‚   â”œâ”€â”€ backtest.py           # BacktestConfig (fees, slippage)
â”‚   â””â”€â”€ risk.py               # RiskConfig (position sizing)
â”œâ”€â”€ configs/                   # Default configuration files
â”œâ”€â”€ strategies/          # Strategy YAML configs (not versioned)
â”œâ”€â”€ data/                      # Data management
â”‚   â”œâ”€â”€ loader.py             # Load OHLCV data (Parquet/CSV)
â”‚   â”œâ”€â”€ validator.py          # Data quality validation
â”‚   â”œâ”€â”€ metadata.py           # Dataset provenance tracking
â”‚   â”œâ”€â”€ generate_metadata.py  # Metadata generation utility
â”‚   â””â”€â”€ raw/                  # Raw OHLCV data storage
â”œâ”€â”€ features/                  # Feature engineering
â”‚   â”œâ”€â”€ engine.py             # Dynamic feature computation
â”‚   â”œâ”€â”€ indicators/           # 8 technical indicators
â”‚   â””â”€â”€ cache/                # Feature cache storage (optional)
â”œâ”€â”€ training/                  # ML training & backtesting
â”‚   â”œâ”€â”€ cli/                  # Training command-line tools
â”‚   â”‚   â”œâ”€â”€ train_model.py    # Main training entry point
â”‚   â”‚   â”œâ”€â”€ run_backtest.py   # Backtesting entry point
â”‚   â”‚   â”œâ”€â”€ validate_model.py # Standalone validation
â”‚   â”‚   â””â”€â”€ optimize_hyperparameters.py # Hyperparameter optimization
â”‚   â”œâ”€â”€ pipeline.py           # TrainingPipeline orchestrator (timing, seeding)
â”‚   â”œâ”€â”€ data_pipeline.py      # Data loading and preparation (schema checks, cache)
â”‚   â”œâ”€â”€ signal_pipeline.py    # Signal generation and filtering (guards regression)
â”‚   â”œâ”€â”€ validator.py          # Walk-forward validation (per-split retrain)
â”‚   â”œâ”€â”€ backtest_pipeline.py  # Backtesting workflow (risk/exec parity)
â”‚   â””â”€â”€ targets.py            # Target variable creation
â”œâ”€â”€ execution/                 # Paper trading & live execution
â”‚   â”œâ”€â”€ cli/                  # Execution command-line tools
â”‚   â”‚   â”œâ”€â”€ run_multi_strategy.py # Multi-strategy paper trading
â”‚   â”‚   â”œâ”€â”€ check_paper_trading_stats.py # Statistics checker
â”‚   â”‚   â”œâ”€â”€ test_websocket_integration.py # WebSocket testing
â”‚   â”‚   â”œâ”€â”€ test_signal_save.py # Signal testing
â”‚   â”‚   â””â”€â”€ debug_kirby_messages.py # Kirby debugging
â”‚   â”œâ”€â”€ portfolio/            # Portfolio coordination & signals
â”‚   â”‚   â”œâ”€â”€ coordinator.py    # PortfolioCoordinator class
â”‚   â”‚   â”œâ”€â”€ position.py       # Position tracking
â”‚   â”‚   â””â”€â”€ signal.py         # StrategySignal class
â”‚   â”œâ”€â”€ inference/            # Model inference for live trading
â”‚   â”œâ”€â”€ persistence/          # Database state management
â”‚   â”œâ”€â”€ risk/                 # Risk management
â”‚   â”œâ”€â”€ runner/               # Live strategy orchestration
â”‚   â”œâ”€â”€ simulator/            # Order execution simulation
â”‚   â”œâ”€â”€ streaming/            # Real-time data processing
â”‚   â”œâ”€â”€ tracking/             # Position management
â”‚   â”œâ”€â”€ websocket/            # Live market data connection
â”‚   â””â”€â”€ state/                # Database files
â”œâ”€â”€ models/                    # Model registry & metadata
â”‚   â”œâ”€â”€ metadata.py           # ModelMetadata (hybrid IDs)
â”‚   â”œâ”€â”€ registry.py           # Centralized model storage
â”‚   â”œâ”€â”€ utils.py              # Model utilities
â”‚   â”œâ”€â”€ trained/              # Serialized models
â”‚   â””â”€â”€ metadata/             # Model metadata (JSON)
â”œâ”€â”€ api/                       # FastAPI REST/WebSocket API
â”‚   â”œâ”€â”€ routers/              # Endpoint routers
â”‚   â”‚   â”œâ”€â”€ strategies.py     # Strategy management
â”‚   â”‚   â”œâ”€â”€ arenas.py         # Arena metadata (exchange, pair, interval)
â”‚   â”‚   â”œâ”€â”€ positions.py      # Position tracking
â”‚   â”‚   â””â”€â”€ trades.py         # Trade history
â”‚   â”œâ”€â”€ services/             # Business logic layer
â”‚   â”œâ”€â”€ schemas/              # Pydantic models
â”‚   â””â”€â”€ websocket/            # Real-time updates
â”œâ”€â”€ tests/                     # Test suite
â”‚   â”œâ”€â”€ unit/                 # Unit tests
â”‚   â””â”€â”€ integration/          # Integration tests
â”‚       â”œâ”€â”€ test_kirby_websocket.py # WebSocket integration
â”‚       â””â”€â”€ test_model_registry_demo.py # Model registry demo
â””â”€â”€ scripts/                   # Development utilities
    â””â”€â”€ verify_imports.py
```

## ğŸ”‘ Core Concepts

### Hybrid Model IDs

Models use hybrid IDs that encode both **what** (configuration) and **when** (training time):

```
Format: {config_hash}_{timestamp}_{random_suffix}
Example: 2e30bea4e8f93845_20251108_153045_a3f9c2
         â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”˜
           Intent      Implementation   Safety
```

**Benefits**:
- Track multiple training runs of same configuration
- Natural chronological ordering
- Find similar models via config hash
- Full audit trail for compliance

### Complete Reproducibility

Every model links to complete provenance chain:

```
Model â†’ ModelMetadata â†’ DatasetMetadata â†’ Raw Data File
  â†“          â†“                 â†“                â†“
Sharpe   Hyperparams      Data Quality      OHLCV
Metrics  Features         99.94%            172K bars
         Training Range   Asset: BTC        July-Nov 2025
```

### Data Leakage Prevention

Strict temporal ordering prevents future data contamination:

```python
# TimeSeriesSplitter ensures:
assert train_max_timestamp < validation_min_timestamp
assert lookback_window < split_start_timestamp
```

## ğŸ“Š Available Components

**Configuration** (6 Pydantic models):
- BaseConfig, DataConfig, FeatureConfig, StrategyConfig, BacktestConfig, RiskConfig

**Data Pipeline**:
- DataLoader (Parquet/CSV), DataValidator, DatasetMetadata

**Feature Engineering** (8 indicators):
- SMA, EMA, RSI, MACD, ROC, Bollinger Bands, ATR, VolumeMA

**Validation**:
- TimeSeriesSplitter, WalkForwardValidator, BacktestEngine, PerformanceMetrics

**Model Registry**:
- ModelMetadata, ModelRegistry, Hybrid ID system

## ğŸ“š Documentation

**Getting Started**:
- [docs/MODEL_TRAINING.md](docs/MODEL_TRAINING.md) - Complete training and validation guide
- [docs/DOCKER.md](docs/DOCKER.md) - Docker deployment and paper trading
- [docs/ACTIVE_FILES.md](docs/ACTIVE_FILES.md) - Codebase structure reference

**API & Integration**:
- [docs/API.md](docs/API.md) - REST API for portfolio management
- [docs/WEBSOCKET.md](docs/WEBSOCKET.md) - Real-time WebSocket connections
- [docs/DATABASE.md](docs/DATABASE.md) - Database schema and operations

**Architecture**:
- [docs/DECISIONS.md](docs/DECISIONS.md) - Key architectural decisions
- [docs/FEATURE_SCHEMA_USAGE.md](docs/FEATURE_SCHEMA_USAGE.md) - Feature engineering details


## ğŸ”¬ Testing

```bash
# Run all tests
pytest tests/unit/ -v

# Current results: 145/145 passing âœ“
# - 28 tests: SignalGenerator (confidence filtering, cooldown, deduplication)
# - 21 tests: ModelPredictor (async inference, caching, feature computation)
# - 28 tests: OrderExecutor (fees, slippage, order validation)
# - 26 tests: Phase 10 features (binary target, confidence sizing, cooldown)
# - 21 tests: Portfolio coordinator
# - 9 tests: Model registry
# - 7 tests: Dataset metadata
# - 5 tests: Hybrid ID system
```

## ğŸ“ Philosophy

1. **Research First**: Optimized for rapid iteration and experimentation
2. **Validation Rigorous**: Walk-forward validation, realistic backtesting
3. **Production Ready**: Well-documented, tested, reproducible
4. **Modular**: Independent strategies, centralized infrastructure

## ğŸ¤ Contributing

See [.claude/PROJECT_CONTEXT.md](.claude/PROJECT_CONTEXT.md) for architectural context and design decisions.

## ğŸ“„ License

[Your License Here]
