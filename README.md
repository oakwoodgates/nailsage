# NailSage

**ML Trading Research Platform for Cryptocurrency Markets**

Named after the Great Nailsage Sly, trainer of the Nailmasters, from Hollow Knight.

## ğŸ¯ Overview

NailSage is a production-ready ML trading research platform designed for building, testing, and deploying machine learning trading strategies with rigorous validation and complete reproducibility.

**Current Status**: Core framework complete (17/25 milestones, 68%) - Ready for first strategy implementation

**Phase 1 Focus**: Classical ML (XGBoost, LightGBM, Random Forest) with walk-forward validation

## âœ¨ Key Features

- **âœ… Complete Metadata Tracking**: Full data and model provenance for reproducibility
- **âœ… Data Leakage Prevention**: Strict temporal ordering with walk-forward validation
- **âœ… Realistic Backtesting**: Transaction costs, slippage, and leverage simulation
- **âœ… Hybrid Model Registry**: Track configuration intent and training history
- **âœ… Dynamic Feature Engineering**: 8 technical indicators computed on-the-fly
- **âœ… Modular Architecture**: Independent strategies with centralized model management

## ğŸš€ Quick Start

### Installation

```bash
# Clone repository
git clone <repository>
cd nailsage

# Install dependencies
pip install -r requirements.txt  # Or use pyproject.toml

# Verify imports
python scripts/verify_imports.py
```

### Generate Data Metadata

```bash
# For a single file
python scripts/generate_data_metadata.py --file data/raw/your_data.parquet

# For entire directory
python scripts/generate_data_metadata.py --dir data/raw
```

### Run Tests

```bash
# Run all tests
pytest tests/unit/ -v

# Run with coverage
pytest tests/unit/ --cov=. --cov-report=term-missing
```

## ğŸ“ Project Structure

```
nailsage/
â”œâ”€â”€ config/                    # Pydantic configuration models
â”‚   â”œâ”€â”€ base.py               # BaseConfig with YAML loading
â”‚   â”œâ”€â”€ data.py               # DataConfig (OHLCV loading)
â”‚   â”œâ”€â”€ feature.py            # FeatureConfig (indicators)
â”‚   â”œâ”€â”€ strategy.py           # StrategyConfig
â”‚   â”œâ”€â”€ backtest.py           # BacktestConfig (fees, slippage)
â”‚   â””â”€â”€ risk.py               # RiskConfig (position sizing)
â”œâ”€â”€ configs/                   # YAML configuration files
â”œâ”€â”€ data/                      # Data management
â”‚   â”œâ”€â”€ loader.py             # Load OHLCV data (Parquet/CSV)
â”‚   â”œâ”€â”€ validator.py          # Data quality validation
â”‚   â”œâ”€â”€ metadata.py           # Dataset provenance tracking
â”‚   â””â”€â”€ raw/                  # Raw OHLCV data storage
â”œâ”€â”€ features/                  # Feature engineering
â”‚   â”œâ”€â”€ engine.py             # Dynamic feature computation
â”‚   â”œâ”€â”€ indicators/           # 8 technical indicators
â”‚   â””â”€â”€ cache/                # Feature cache storage
â”œâ”€â”€ validation/                # Validation framework
â”‚   â”œâ”€â”€ time_series_split.py # Walk-forward splitting
â”‚   â”œâ”€â”€ backtest.py           # Backtesting engine
â”‚   â”œâ”€â”€ metrics.py            # Performance metrics
â”‚   â””â”€â”€ walk_forward.py       # Complete validation pipeline
â”œâ”€â”€ models/                    # Model registry & metadata
â”‚   â”œâ”€â”€ metadata.py           # ModelMetadata (hybrid IDs)
â”‚   â”œâ”€â”€ registry.py           # Centralized model storage
â”‚   â”œâ”€â”€ utils.py              # Model utilities
â”‚   â”œâ”€â”€ trained/              # Serialized models
â”‚   â””â”€â”€ metadata/             # Model metadata (JSON)
â”œâ”€â”€ strategies/                # Strategy implementations
â”‚   â”œâ”€â”€ short_term/           # Short-term strategies
â”‚   â””â”€â”€ long_term/            # Long-term strategies
â”œâ”€â”€ tests/                     # Test suite (21 passing tests)
â”‚   â”œâ”€â”€ unit/                 # Unit tests
â”‚   â””â”€â”€ integration/          # Integration tests
â””â”€â”€ scripts/                   # Helper scripts
    â”œâ”€â”€ generate_data_metadata.py
    â”œâ”€â”€ test_model_registry.py
    â””â”€â”€ verify_imports.py
```

## ğŸ”‘ Core Concepts

### Hybrid Model IDs

Models use hybrid IDs that encode both **what** (configuration) and **when** (training time):

```
Format: {config_hash}_{timestamp}_{random_suffix}
Example: 2e30bea4e8f93845_20251108_153045_a3f9c2
         â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”˜
           Intent      Implementation   Safety
```

**Benefits**:
- Track multiple training runs of same configuration
- Natural chronological ordering
- Find similar models via config hash
- Full audit trail for compliance

### Complete Reproducibility

Every model links to complete provenance chain:

```
Model â†’ ModelMetadata â†’ DatasetMetadata â†’ Raw Data File
  â†“          â†“                 â†“                â†“
Sharpe   Hyperparams      Data Quality      OHLCV
Metrics  Features         99.94%            172K bars
         Training Range   Asset: BTC        July-Nov 2025
```

### Data Leakage Prevention

Strict temporal ordering prevents future data contamination:

```python
# TimeSeriesSplitter ensures:
assert train_max_timestamp < validation_min_timestamp
assert lookback_window < split_start_timestamp
```

## ğŸ“Š Available Components

**Configuration** (6 Pydantic models):
- BaseConfig, DataConfig, FeatureConfig, StrategyConfig, BacktestConfig, RiskConfig

**Data Pipeline**:
- DataLoader (Parquet/CSV), DataValidator, DatasetMetadata

**Feature Engineering** (8 indicators):
- SMA, EMA, RSI, MACD, ROC, Bollinger Bands, ATR, VolumeMA

**Validation**:
- TimeSeriesSplitter, WalkForwardValidator, BacktestEngine, PerformanceMetrics

**Model Registry**:
- ModelMetadata, ModelRegistry, Hybrid ID system

## ğŸ“ Next Steps

**Ready to implement your first strategy?** See [STRATEGY_GUIDE.md](docs/STRATEGY_GUIDE.md) for a complete walkthrough.

**Key Documentation**:
- [.claude/PROJECT_CONTEXT.md](.claude/PROJECT_CONTEXT.md) - Complete project overview
- [.claude/STATUS.md](.claude/STATUS.md) - Current status and progress
- [.claude/DECISIONS.md](.claude/DECISIONS.md) - Architectural Decision Records
- [docs/STRATEGY_GUIDE.md](docs/STRATEGY_GUIDE.md) - Strategy implementation guide

## ğŸ“ˆ Current Status

**Completed** (17 milestones):
- âœ… Project infrastructure & configuration system
- âœ… Logging infrastructure
- âœ… Data pipeline with quality validation
- âœ… Feature engineering (8 indicators)
- âœ… Data leakage prevention
- âœ… Validation framework (walk-forward, backtesting)
- âœ… Dataset metadata tracking
- âœ… Model registry with hybrid IDs
- âœ… Unit tests (21 passing)

**Next Up**:
- First strategy implementation (BTC perps, momentum-based)
- Second strategy (modularity proof)
- Paper trading integration
- Docker deployment

## ğŸ”¬ Testing

```bash
# Run all tests
pytest tests/unit/ -v

# Current results: 21/21 passing âœ“
# - 7 tests: Dataset metadata
# - 9 tests: Model registry
# - 5 tests: Hybrid ID system
```

## ğŸ“ Philosophy

1. **Research First**: Optimized for rapid iteration and experimentation
2. **Validation Rigorous**: Walk-forward validation, realistic backtesting
3. **Production Ready**: Well-documented, tested, reproducible
4. **Modular**: Independent strategies, centralized infrastructure

## ğŸ¤ Contributing

See [.claude/PROJECT_CONTEXT.md](.claude/PROJECT_CONTEXT.md) for architectural context and design decisions.

## ğŸ“„ License

[Your License Here]
