# NailSage

**ML Trading Research Platform for Cryptocurrency Markets**

Named after the Great Nailsage Sly, trainer of the Nailmasters, from Hollow Knight.

## ğŸ¯ Overview

NailSage is a production-ready ML trading research platform designed for building, testing, and deploying machine learning trading strategies with rigorous validation and complete reproducibility.

**Current Status**: MVP Complete (35/35 milestones, 100%) âœ… - Paper trading operational with model quality improvements

**Phase 1 Focus**: Classical ML (XGBoost, LightGBM, Random Forest) with walk-forward validation

## âœ¨ Key Features

- **âœ… Complete Metadata Tracking**: Full data and model provenance for reproducibility
- **âœ… Data Leakage Prevention**: Strict temporal ordering with walk-forward validation
- **âœ… Realistic Backtesting**: Transaction costs, slippage, and leverage simulation
- **âœ… Hybrid Model Registry**: Track configuration intent and training history
- **âœ… Dynamic Feature Engineering**: 18 technical indicators computed on-the-fly
- **âœ… Modular Architecture**: Independent strategies with centralized model management
- **âœ… Binary Classification Models**: Phase 10 aggressive trading with SHORT/LONG signals
- **âœ… Confidence-Based Filtering**: Minimum confidence thresholds for signal generation
- **âœ… Signal Cooldown**: Prevents spam with minimum bars between signals
- **âœ… Real-Time P&L Updates**: Position profitability updated every candle
- **âœ… Transparent Decision Logging**: See why signals are generated or suppressed
- **âœ… Smart Feature Caching**: Enabled for training/backtesting, disabled for live trading
- **âœ… Per-Strategy Bankroll**: Isolated $10k bankroll per strategy with percentage-based sizing
- **âœ… Automatic Position Sizing**: Trades sized at 10% of current strategy bankroll
- **âœ… Bankroll Depletion Protection**: Strategies auto-pause when bankroll <= $0
- **âœ… Arena Metadata**: Trading arena data (exchange, pair, interval) synced from Kirby API

## ğŸš€ Quick Start

### Installation

```bash
# Clone repository
git clone <repository>
cd nailsage

# Install dependencies
pip install -r requirements.txt  # Or use pyproject.toml

# Verify imports
python scripts/verify_imports.py
```

### Generate Data Metadata

```bash
# For a single file
python scripts/generate_data_metadata.py --file data/raw/your_data.parquet

# For entire directory
python scripts/generate_data_metadata.py --dir data/raw
```

### Train and Validate Models

```bash
# Train with walk-forward validation (saves results to JSON)
python training/cli/train_model.py --config configs/strategies/dev_scalper_1m_v1.yaml

# Validate existing model
python training/cli/validate_model.py --config configs/strategies/dev_scalper_1m_v1.yaml --model-id MODEL_ID

# Quick backtest
python training/cli/run_backtest.py --config configs/strategies/dev_scalper_1m_v1.yaml --model-id MODEL_ID
```

### Run Tests

```bash
# Run all tests
pytest tests/unit/ -v

# Run with coverage
pytest tests/unit/ --cov=. --cov-report=term-missing
```

### ğŸ³ Docker Quick Start (Recommended for Paper Trading)

Run strategies in production-ready Docker containers with PostgreSQL:

```bash
# 1. Configure environment
cp .env.example .env
# Edit .env with your Kirby API credentials

# 2. Start all services
docker compose up -d

# 3. View logs
docker logs nailsage-binance -f

# 4. Check status
docker compose ps

# 5. Stop services
docker compose down
```

**What's running:**
- PostgreSQL database (port 5433)
- FastAPI dashboard API (port 8001)
- Strategy containers (Binance, Hyperliquid)

**Development workflow:**
```bash
# Make code changes, then rebuild
docker compose build nailsage-binance && docker compose up -d nailsage-binance

# View live predictions
docker logs nailsage-binance --tail 100 -f
```

**Full documentation:** See [docs/DOCKER.md](docs/DOCKER.md) for complete setup, deployment, and troubleshooting guides.

## ğŸ“ Project Structure

```
nailsage/
â”œâ”€â”€ config/                    # Pydantic configuration models
â”‚   â”œâ”€â”€ base.py               # BaseConfig with YAML loading
â”‚   â”œâ”€â”€ data.py               # DataConfig (OHLCV loading)
â”‚   â”œâ”€â”€ feature.py            # FeatureConfig (indicators)
â”‚   â”œâ”€â”€ strategy.py           # StrategyConfig
â”‚   â”œâ”€â”€ backtest.py           # BacktestConfig (fees, slippage)
â”‚   â””â”€â”€ risk.py               # RiskConfig (position sizing)
â”œâ”€â”€ configs/                   # YAML configuration files
â”œâ”€â”€ data/                      # Data management
â”‚   â”œâ”€â”€ loader.py             # Load OHLCV data (Parquet/CSV)
â”‚   â”œâ”€â”€ validator.py          # Data quality validation
â”‚   â”œâ”€â”€ metadata.py           # Dataset provenance tracking
â”‚   â””â”€â”€ raw/                  # Raw OHLCV data storage
â”œâ”€â”€ features/                  # Feature engineering
â”‚   â”œâ”€â”€ engine.py             # Dynamic feature computation
â”‚   â”œâ”€â”€ indicators/           # 8 technical indicators
â”‚   â””â”€â”€ cache/                # Feature cache storage
â”œâ”€â”€ training/                  # ML training & backtesting
â”‚   â”œâ”€â”€ cli/                  # Training command-line tools
â”‚   â”‚   â”œâ”€â”€ train_model.py    # Main training entry point
â”‚   â”‚   â”œâ”€â”€ run_backtest.py   # Backtesting entry point
â”‚   â”‚   â”œâ”€â”€ validate_model.py # Standalone validation
â”‚   â”‚   â””â”€â”€ optimize_hyperparameters.py # Hyperparameter optimization
â”‚   â”œâ”€â”€ pipeline.py           # TrainingPipeline orchestrator
â”‚   â”œâ”€â”€ data_pipeline.py      # Data loading and preparation
â”‚   â”œâ”€â”€ signal_pipeline.py    # Signal generation and filtering
â”‚   â”œâ”€â”€ validator.py          # Walk-forward validation
â”‚   â”œâ”€â”€ backtest_pipeline.py  # Backtesting workflow
â”‚   â””â”€â”€ targets.py            # Target variable creation
â”œâ”€â”€ execution/                 # Paper trading & live execution
â”‚   â”œâ”€â”€ cli/                  # Execution command-line tools
â”‚   â”‚   â”œâ”€â”€ run_multi_strategy.py # Multi-strategy paper trading
â”‚   â”‚   â”œâ”€â”€ check_paper_trading_stats.py # Statistics checker
â”‚   â”‚   â”œâ”€â”€ test_websocket_integration.py # WebSocket testing
â”‚   â”‚   â”œâ”€â”€ test_signal_save.py # Signal testing
â”‚   â”‚   â””â”€â”€ debug_kirby_messages.py # Kirby debugging
â”‚   â”œâ”€â”€ inference/            # Model inference for live trading
â”‚   â”œâ”€â”€ persistence/          # Database state management
â”‚   â”œâ”€â”€ risk/                 # Risk management
â”‚   â”œâ”€â”€ runner/               # Live strategy orchestration
â”‚   â”œâ”€â”€ simulator/            # Order execution simulation
â”‚   â”œâ”€â”€ streaming/            # Real-time data processing
â”‚   â”œâ”€â”€ tracking/             # Position management
â”‚   â”œâ”€â”€ websocket/            # Live market data connection
â”‚   â””â”€â”€ state/                # Database files
â”œâ”€â”€ models/                    # Model registry & metadata
â”‚   â”œâ”€â”€ metadata.py           # ModelMetadata (hybrid IDs)
â”‚   â”œâ”€â”€ registry.py           # Centralized model storage
â”‚   â”œâ”€â”€ utils.py              # Model utilities
â”‚   â”œâ”€â”€ trained/              # Serialized models
â”‚   â””â”€â”€ metadata/             # Model metadata (JSON)
â”œâ”€â”€ api/                       # FastAPI REST/WebSocket API
â”‚   â”œâ”€â”€ routers/              # Endpoint routers
â”‚   â”‚   â”œâ”€â”€ strategies.py     # Strategy management
â”‚   â”‚   â”œâ”€â”€ arenas.py         # Arena metadata (exchange, pair, interval)
â”‚   â”‚   â”œâ”€â”€ positions.py      # Position tracking
â”‚   â”‚   â””â”€â”€ trades.py         # Trade history
â”‚   â”œâ”€â”€ services/             # Business logic layer
â”‚   â”œâ”€â”€ schemas/              # Pydantic models
â”‚   â””â”€â”€ websocket/            # Real-time updates
â”œâ”€â”€ tests/                     # Test suite
â”‚   â”œâ”€â”€ unit/                 # Unit tests
â”‚   â””â”€â”€ integration/          # Integration tests
â””â”€â”€ scripts/                   # System administration scripts
    â”œâ”€â”€ generate_data_metadata.py
    â”œâ”€â”€ migrate_arenas.py
    â”œâ”€â”€ test_historical_candles.py
    â”œâ”€â”€ test_model_registry.py
    â””â”€â”€ verify_imports.py
```

## ğŸ”‘ Core Concepts

### Hybrid Model IDs

Models use hybrid IDs that encode both **what** (configuration) and **when** (training time):

```
Format: {config_hash}_{timestamp}_{random_suffix}
Example: 2e30bea4e8f93845_20251108_153045_a3f9c2
         â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”˜
           Intent      Implementation   Safety
```

**Benefits**:
- Track multiple training runs of same configuration
- Natural chronological ordering
- Find similar models via config hash
- Full audit trail for compliance

### Complete Reproducibility

Every model links to complete provenance chain:

```
Model â†’ ModelMetadata â†’ DatasetMetadata â†’ Raw Data File
  â†“          â†“                 â†“                â†“
Sharpe   Hyperparams      Data Quality      OHLCV
Metrics  Features         99.94%            172K bars
         Training Range   Asset: BTC        July-Nov 2025
```

### Data Leakage Prevention

Strict temporal ordering prevents future data contamination:

```python
# TimeSeriesSplitter ensures:
assert train_max_timestamp < validation_min_timestamp
assert lookback_window < split_start_timestamp
```

## ğŸ“Š Available Components

**Configuration** (6 Pydantic models):
- BaseConfig, DataConfig, FeatureConfig, StrategyConfig, BacktestConfig, RiskConfig

**Data Pipeline**:
- DataLoader (Parquet/CSV), DataValidator, DatasetMetadata

**Feature Engineering** (8 indicators):
- SMA, EMA, RSI, MACD, ROC, Bollinger Bands, ATR, VolumeMA

**Validation**:
- TimeSeriesSplitter, WalkForwardValidator, BacktestEngine, PerformanceMetrics

**Model Registry**:
- ModelMetadata, ModelRegistry, Hybrid ID system

## ğŸ“ Next Steps

**Ready to train your first model?** See [MODEL_TRAINING.md](docs/MODEL_TRAINING.md) for comprehensive training and validation guide.

**Key Documentation**:
- [docs/MODEL_TRAINING.md](docs/MODEL_TRAINING.md) - Training, validation, and backtesting guide
- [docs/API.md](docs/API.md) - REST API reference (strategies, arenas, trades, positions)
- [docs/DOCKER.md](docs/DOCKER.md) - Docker deployment guide
- [docs/STRATEGY_GUIDE.md](docs/STRATEGY_GUIDE.md) - Strategy implementation guide (legacy)
- [.claude/PROJECT_CONTEXT.md](.claude/PROJECT_CONTEXT.md) - Complete project overview
- [.claude/STATUS.md](.claude/STATUS.md) - Current status and progress
- [.claude/DECISIONS.md](.claude/DECISIONS.md) - Architectural Decision Records

## ğŸ“ˆ Current Status

**MVP Complete** (35/35 milestones): âœ…
- âœ… Core infrastructure & configuration (Phases 1-5)
- âœ… Data pipeline with quality validation
- âœ… Feature engineering (10 indicators)
- âœ… Validation framework (walk-forward, backtesting)
- âœ… Model registry with hybrid IDs
- âœ… Multi-algorithm support (XGBoost, LightGBM, RandomForest, ExtraTrees)
- âœ… Portfolio coordination system
- âœ… Paper trading infrastructure (Phase 8-9)
  - WebSocket client with Kirby API integration
  - Live inference pipeline
  - State persistence (SQLite)
- âœ… Model quality improvements (Phase 10)
  - Binary classification support
  - Confidence-based position sizing
  - Trade cooldown mechanism
  - Hyperparameter optimization
- âœ… Unit tests (145 passing)

**Ready for Production Testing**:
- Paper trading validation with real models
- Extended monitoring and performance tracking

## ğŸ”¬ Testing

```bash
# Run all tests
pytest tests/unit/ -v

# Current results: 145/145 passing âœ“
# - 28 tests: SignalGenerator (confidence filtering, cooldown, deduplication)
# - 21 tests: ModelPredictor (async inference, caching, feature computation)
# - 28 tests: OrderExecutor (fees, slippage, order validation)
# - 26 tests: Phase 10 features (binary target, confidence sizing, cooldown)
# - 21 tests: Portfolio coordinator
# - 9 tests: Model registry
# - 7 tests: Dataset metadata
# - 5 tests: Hybrid ID system
```

## ğŸ“ Philosophy

1. **Research First**: Optimized for rapid iteration and experimentation
2. **Validation Rigorous**: Walk-forward validation, realistic backtesting
3. **Production Ready**: Well-documented, tested, reproducible
4. **Modular**: Independent strategies, centralized infrastructure

## ğŸ¤ Contributing

See [.claude/PROJECT_CONTEXT.md](.claude/PROJECT_CONTEXT.md) for architectural context and design decisions.

## ğŸ“„ License

[Your License Here]
